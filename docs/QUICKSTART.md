## Quick Start Guide

**â±ï¸ Time to running system: 5 minutes**

### What You'll Get

- âœ… AI-powered lead search (using Groq API)
- âœ… Machine learning scoring (predicts conversion probability)
- âœ… Real-time dashboard (Angular frontend)
- âœ… REST API (FastAPI backend)
- âœ… PostgreSQL database
- âœ… Fully containerized with Docker

### Prerequisites

```bash
# Check you have these installed
docker --version      # Docker 24+
docker-compose --version  # Docker Compose 2+
node --version        # Node 18+ (optional, for frontend dev)
python3 --version     # Python 3.11+ (optional, for backend dev)
```

**Don't have Docker?**
- Mac: https://www.docker.com/products/docker-desktop
- Windows: https://www.docker.com/products/docker-desktop
- Linux: `sudo apt-get install docker.io docker-compose`

### Get Groq API Key (2 minutes)

The system uses **Groq LLM** to generate realistic leads from search queries.

1. Go to https://console.groq.com
2. Click "Sign Up" (if new user)
3. Verify email
4. Click "API Keys" in left menu
5. Click "Create New API Key"
6. Copy the key (format: `gsk_xxxxxxxxxxxxxxxx`)

**Save this key - you'll need it next!**

### Setup & Start (3 minutes)

```bash
# 1. Clone the repository
git clone https://github.com/dlai-sd/yashus.git
cd yashus

# 2. Create .env file with your Groq API key
cat > TheHunter/backend/.env << 'EOF'
DATABASE_URL=postgresql://hunter:hunter_password@localhost:5432/hunter_db
GROQ_API_KEY=gsk_your_api_key_here_replace_this
DEBUG=false
SECRET_KEY=dev-secret-key-change-in-production
ALGORITHM=HS256
ALLOWED_ORIGINS=http://localhost:4200
EOF

# 3. Run setup script (builds images, starts containers)
bash common/scripts/setup-local.sh

# 4. Wait for containers to start (about 30-60 seconds)
# You'll see: "âœ… All services healthy!"
```

**That's it! Your system is running!**

### Access The Application

| Service | URL | Purpose |
|---------|-----|---------|
| **Frontend** | http://localhost:4200 | The Hunter dashboard |
| **API Docs** | http://localhost:8000/docs | Interactive API documentation |
| **API** | http://localhost:8000 | Backend API |

### Test The System

**Option 1: Use the Web Interface**

1. Open http://localhost:4200 in your browser
2. Go to "Recipe Executor" section
3. Enter search query: `"Dentist doctor in viman nagar Pune India"`
4. Click "Execute"
5. Watch real leads appear with ML predictions:
   - âœ… Rahul Sharma at Smile Care Dental Clinic
   - âœ… Aisha Khan at Dental Hub
   - âœ… 3 more dentists with conversion probability predictions

**Expected Results:**
- Leads show `"source": "ai_search"` (not mock data) âœ…
- Each lead has conversion probability (44-48%)
- Confidence scores and risk levels calculated
- Full contact details visible

**Option 2: Use the API**

```bash
# Get your customer ID from database
CUSTOMER_ID=$(docker-compose -f TheHunter/docker-compose.yml exec db \
  psql -U hunter -d hunter_db -t -c "SELECT id FROM customers LIMIT 1")

AGENT_ID=$(docker-compose -f TheHunter/docker-compose.yml exec db \
  psql -U hunter -d hunter_db -t -c "SELECT id FROM agents LIMIT 1")

# Make API call
curl -X POST http://localhost:8000/api/v1/recipes/execute \
  -H "Content-Type: application/json" \
  -d "{
    \"customer_id\": \"$CUSTOMER_ID\",
    \"agent_id\": \"$AGENT_ID\",
    \"recipe_id\": \"discovery\",
    \"input_data\": {
      \"search_query\": \"Dentist doctor in viman nagar Pune India\",
      \"limit\": 5
    }
  }"

# You'll get back 5 dentist leads with ML scores
```

### Common Commands

**View Logs:**
```bash
# All services
docker-compose -f TheHunter/docker-compose.yml logs -f

# Just backend
docker-compose -f TheHunter/docker-compose.yml logs -f backend

# Just frontend
docker-compose -f TheHunter/docker-compose.yml logs -f frontend

# Search for errors
docker-compose logs backend | grep -i "error\|failed"
```

**Access Database:**
```bash
docker-compose -f TheHunter/docker-compose.yml exec db \
  psql -U hunter -d hunter_db

# In psql:
\dt              # List all tables
SELECT * FROM customers;  # View customers
SELECT * FROM lead_feedback;  # View training data
\q               # Exit
```

**Restart Services:**
```bash
# Restart everything
docker-compose -f TheHunter/docker-compose.yml down
docker-compose -f TheHunter/docker-compose.yml up

# Just restart backend (e.g., after code changes)
docker-compose -f TheHunter/docker-compose.yml restart backend
```

**Stop Services:**
```bash
# Stop without deleting data
docker-compose -f TheHunter/docker-compose.yml stop

# Stop and delete everything (keeps data in volumes)
docker-compose -f TheHunter/docker-compose.yml down

# Stop and delete EVERYTHING including data
docker-compose -f TheHunter/docker-compose.yml down -v
```

### Project Structure

```
yashus/
â”œâ”€â”€ TheHunter/                           # Main application
â”‚   â”œâ”€â”€ backend/                         # FastAPI (Python)
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”‚   â”‚   â”œâ”€â”€ components.py           # Recipe components (AI, Actions)
â”‚   â”‚   â”‚   â”œâ”€â”€ executor.py             # Pipeline executor
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.py               # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py             # PostgreSQL setup
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py               # Data models
â”‚   â”‚   â”‚   â””â”€â”€ ml/
â”‚   â”‚   â”‚       â”œâ”€â”€ trainer.py          # ML model training
â”‚   â”‚   â”‚       â””â”€â”€ feature_extractor.py  # Feature engineering
â”‚   â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚   â””â”€â”€ mock_leads.py           # Mock data for fallback
â”‚   â”‚   â”œâ”€â”€ .env                        # Environment variables
â”‚   â”‚   â”œâ”€â”€ Dockerfile                  # Container definition
â”‚   â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/                        # Angular 17 (TypeScript)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ recipe-executor/  # Search & results
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ calculator.service.ts  # API client
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ app.module.ts       # Main module
â”‚   â”‚   â”‚   â”œâ”€â”€ main.ts
â”‚   â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ Dockerfile                  # Container definition
â”‚   â”‚   â”œâ”€â”€ nginx.conf                  # Web server config
â”‚   â”‚   â””â”€â”€ package.json                # Node dependencies
â”‚   â”‚
â”‚   â””â”€â”€ docker-compose.yml              # Orchestration
â”‚
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ setup-local.sh              # â† RUN THIS!
â”‚   â”‚   â”œâ”€â”€ setup-from-config.sh        # Alternative setup
â”‚   â”‚   â””â”€â”€ run-tests.sh                # Test runner
â”‚   â””â”€â”€ .env.example                    # Environment template
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ QUICKSTART.md                   # â† You are here
    â”œâ”€â”€ ML_AND_SEARCH_SYSTEM.md         # How AI search & ML scoring works
    â”œâ”€â”€ ENVIRONMENT_SETUP.md            # Configuration details
    â”œâ”€â”€ ARCHITECTURE.md                 # Complete system design
    â””â”€â”€ ...
```

### File Descriptions

| File | Purpose |
|------|---------|
| `TheHunter/backend/.env` | **Environment variables (API keys, DB URL, etc.)** |
| `TheHunter/backend/app/components.py` | Recipe components: AI search expansion, lead discovery, dedup, ML scoring |
| `TheHunter/backend/app/executor.py` | Runs recipe pipeline (orchestrates 4 components) |
| `TheHunter/backend/app/ml/trainer.py` | Trains RandomForest model on lead_feedback data |
| `TheHunter/backend/scripts/mock_leads.py` | Mock data (used when Groq API fails) |
| `TheHunter/frontend/src/app/components/recipe-executor/` | Search input & results display |

### API Endpoints

**Execute Recipe (Main Endpoint)**
```
POST /api/v1/recipes/execute
Content-Type: application/json

{
  "customer_id": "uuid",
  "agent_id": "uuid",
  "recipe_id": "discovery",
  "input_data": {
    "search_query": "your search here",
    "limit": 5
  }
}

Returns: {
  "recipe_id": "discovery",
  "status": "success",
  "data": {
    "action_result": [
      {
        "name": "Rahul Sharma",
        "email": "rahul@smilecare.in",
        "source": "ai_search",
        "ml_score": {
          "conversion_probability": 0.44,
          "confidence_score": 12,
          "risk_level": "medium"
        }
      },
      ...
    ]
  },
  "metadata": {
    "duration_ms": 1850,
    "components_executed": 4
  }
}
```

**List Recipes**
```
GET /api/v1/recipes
```

**Get Execution History**
```
GET /api/v1/executions?agent_id=<uuid>&limit=10
```

**Interactive API Docs**
```
http://localhost:8000/docs  (Swagger UI)
http://localhost:8000/redoc (ReDoc)
```

### How It Works (Step by Step)

```
User enters: "Dentist doctor in viman nagar Pune India"
                            â†“
                 [Groq AI - Query Expansion]
                 Generates variations for better coverage
                            â†“
              [Groq AI - Lead Generation]
              Generates 5 realistic dentist leads with:
              - Names, emails, companies
              - Industry, location matching search
              - Engagement scores (0-100%)
                            â†“
                [Deduplication Component]
                Removes duplicate leads by email
                            â†“
              [ML Scoring Component]
              Loads RandomForest model, extracts 10 features:
              - Engagement score, industry match, seniority
              - Company size, location match, lead age
              - Quality score, feedback count, conversion rate
              - Recency score
              Predicts for each lead:
              - Conversion probability (44-48%)
              - Confidence score (0-100)
              - Risk level (Low/Medium/High)
                            â†“
          [Frontend Display - Real-time Dashboard]
          Shows all leads with conversion predictions
          âœ… Rahul Sharma (44% conversion, Medium risk)
          âœ… Aisha Khan (44% conversion, Medium risk)
          âœ… ...
```

### When Does It Use Mock Data?

The system **falls back to mock data** (pre-defined SaaS leads) only when:
- âŒ `GROQ_API_KEY` not set in `.env`
- âŒ API key is invalid/expired
- âŒ Network error or API timeout (>30 seconds)
- âŒ JSON parsing fails (bad API response)
- âŒ Rate limited or quota exceeded

**You'll know it's using mock data when:**
- Search results show SaaS companies (Sarah Chen, Marcus Johnson, etc.) instead of your query
- Response field shows `"source": "mock"` instead of `"ai_search"`
- Backend logs show: `[SEARCH] Falling back to mock leads`

**Solution:** Check `.env` for valid Groq API key and restart backend.

See [ML_AND_SEARCH_SYSTEM.md](ML_AND_SEARCH_SYSTEM.md) for detailed fallback logic.

### Troubleshooting

**Getting mock data instead of real leads?**
```bash
# 1. Check API key is set
grep GROQ_API_KEY TheHunter/backend/.env

# 2. Key must start with 'gsk_'
# If blank or 'gsk_xxx', set to your real key

# 3. Restart backend
docker-compose -f TheHunter/docker-compose.yml restart backend

# 4. Check logs
docker-compose logs backend | grep "AI SEARCH"
# Should show: [AI SEARCH] Generated 5 leads
# Not: [SEARCH] Falling back to mock leads
```

**Port already in use?**
```bash
# Find process using port 4200
lsof -i :4200
# Kill it
kill -9 <PID>
# Try again
docker-compose -f TheHunter/docker-compose.yml up
```

**Database connection error?**
```bash
# Restart database
docker-compose -f TheHunter/docker-compose.yml restart db
# Wait 10 seconds
# Restart backend
docker-compose -f TheHunter/docker-compose.yml restart backend
```

**Containers won't start?**
```bash
# Full reset
docker-compose -f TheHunter/docker-compose.yml down -v
# Run setup again
bash common/scripts/setup-local.sh
```

### Next Steps

1. âœ… System is running!
2. ğŸ“– Read [ML_AND_SEARCH_SYSTEM.md](ML_AND_SEARCH_SYSTEM.md) to understand how it works
3. ğŸ”§ Check [ENVIRONMENT_SETUP.md](ENVIRONMENT_SETUP.md) for configuration options
4. ğŸ—ï¸ Review [ARCHITECTURE.md](ARCHITECTURE.md) for complete system design
5. â˜ï¸ Deploy to Azure using [AZURE_DEPLOYMENT_GUIDE.md](../AZURE_DEPLOYMENT_GUIDE.md)

### Support

**Check API Documentation:**
http://localhost:8000/docs

**View Backend Logs:**
```bash
docker-compose -f TheHunter/docker-compose.yml logs -f backend
```

**Reset Everything:**
```bash
docker-compose -f TheHunter/docker-compose.yml down -v
bash common/scripts/setup-local.sh
```

---

**Ready to hunt some leads? ğŸ¯ Go to http://localhost:4200**

### Project Structure

```
yashus/
â”œâ”€â”€ common/                              # Shared infrastructure
â”‚   â”œâ”€â”€ .github/workflows/
â”‚   â”‚   â””â”€â”€ deploy.yml                  # CI/CD pipeline (manual trigger)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ setup-local.sh              # Local setup script
â”‚   â”‚   â””â”€â”€ run-tests.sh                # Test runner
â”‚   â”œâ”€â”€ .env.example                     # Environment template
â”‚   â””â”€â”€ config/                          # Shared configuration
â”‚
â”œâ”€â”€ TheHunter/                           # Main application
â”‚   â”œâ”€â”€ backend/                         # FastAPI application
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py             # Database setup
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py               # SQLAlchemy models
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py              # Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ services.py             # Business logic
â”‚   â”‚   â”‚   â””â”€â”€ routes.py               # API routes
â”‚   â”‚   â”œâ”€â”€ tests/                      # Test suite
â”‚   â”‚   â”œâ”€â”€ Dockerfile                  # Backend container
â”‚   â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/                        # Angular application
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ app.module.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ app.component.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ calculator/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ calculator.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ main.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”‚   â””â”€â”€ styles.css
â”‚   â”‚   â”œâ”€â”€ Dockerfile                  # Frontend container
â”‚   â”‚   â”œâ”€â”€ nginx.conf                  # Nginx configuration
â”‚   â”‚   â””â”€â”€ package.json                # Node dependencies
â”‚   â”‚
â”‚   â””â”€â”€ docker-compose.yml              # Local orchestration
â”‚
â”œâ”€â”€ README.md                             # Project documentation
â””â”€â”€ LICENSE
```

### Available Commands

**Development:**
```bash
# Start all services
docker-compose -f ./TheHunter/docker-compose.yml up

# Stop all services
docker-compose -f ./TheHunter/docker-compose.yml down

# View logs
docker-compose -f ./TheHunter/docker-compose.yml logs -f

# Access API shell
docker-compose -f ./TheHunter/docker-compose.yml exec api bash
```

**Testing:**
```bash
# Run all tests
./common/scripts/run-tests.sh

# Backend tests only
docker-compose -f ./TheHunter/docker-compose.yml exec api pytest tests/ -v

# Frontend tests only
docker-compose -f ./TheHunter/docker-compose.yml exec frontend npm test
```

**Database:**
```bash
# Access PostgreSQL
docker-compose -f ./TheHunter/docker-compose.yml exec db psql -U hunter -d hunter_db

# Reset database
docker-compose -f ./TheHunter/docker-compose.yml exec api alembic downgrade base
docker-compose -f ./TheHunter/docker-compose.yml exec api alembic upgrade head
```

### CI/CD Pipeline

The GitHub Actions workflow is **manually triggered only** (no auto-trigger on commit).

**To trigger deployment:**
1. Go to: Actions â†’ Build & Deploy - Manual Trigger
2. Click "Run workflow"
3. Select environment: `staging` or `production`
4. Workflow executes: Test â†’ Code Quality â†’ Build â†’ Deploy

**Secrets Required (GitHub Settings â†’ Secrets and variables â†’ Actions):**
- `AZURE_CREDENTIALS`: Azure service principal JSON
- `AZURE_REGISTRY_USERNAME`: Container registry username
- `AZURE_REGISTRY_PASSWORD`: Container registry password
- `AZURE_RESOURCE_GROUP`: Azure resource group name
- `STAGING_DATABASE_URL`: Staging database connection string
- `DEPLOYED_URL`: Deployed application URL for smoke tests

### API Endpoints

**Calculator:**
- `POST /api/v1/calculator/calculate` - Perform calculation
  ```json
  {
    "operation": "add|subtract|multiply|divide",
    "operand1": 10,
    "operand2": 5
  }
  ```
- `GET /api/v1/calculator/history` - Get calculation history
- `GET /api/v1/calculator/calculation/{id}` - Get specific calculation
- `GET /api/v1/calculator/health` - Health check

**Interactive API Documentation:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### Configuration

Create a `.env` file in the `common/` directory (template: `.env.example`):

```env
# Backend
DATABASE_URL=postgresql://hunter:hunter_password@db:5432/hunter_db
ALLOWED_ORIGINS=http://localhost:4200,http://localhost:3000
DEBUG=true
SECRET_KEY=your-secret-key
ALGORITHM=HS256

# Frontend
API_BASE_URL=http://localhost:8000
```

### Troubleshooting

**Port already in use:**
```bash
# Find and kill process using port
lsof -i :8000  # for API
lsof -i :4200  # for Frontend
lsof -i :5432  # for Database
kill -9 <PID>
```

**Database connection issues:**
```bash
# Verify database is healthy
docker-compose -f ./TheHunter/docker-compose.yml ps

# Check database logs
docker-compose -f ./TheHunter/docker-compose.yml logs db
```

**Clear everything and restart:**
```bash
docker-compose -f ./TheHunter/docker-compose.yml down -v
docker system prune -a
./common/scripts/setup-local.sh
```

### Next Steps

1. **Run the calculator** to verify full stack works
2. **Understand the test coverage** in `TheHunter/backend/tests/`
3. **Implement The Hunter modules**:
   - Scraper (Google Maps)
   - Enricher (Website crawling)
   - Brain (LLM integration)
   - Output (Database & exports)
4. **Deploy to Azure** using the manual trigger workflow

### Technology Stack

- **Backend**: Python, FastAPI, SQLAlchemy, PostgreSQL
- **Frontend**: Angular 17, Tailwind CSS, RxJS
- **Infrastructure**: Docker, Docker Compose, Azure
- **Testing**: pytest, Jasmine/Karma
- **CI/CD**: GitHub Actions, Azure Container Registry, Azure App Service

### Support

For issues or questions, check:
1. Logs: `docker-compose logs -f`
2. API Docs: http://localhost:8000/docs
3. GitHub Issues: [Project Board]

---

**Happy Hunting! ğŸ¯**
